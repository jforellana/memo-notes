# Memo Notes Transcriber

A lightweight FastAPI application with a static frontend that lets you upload `.mp3`, `.mp4`, and other common audio/video files and returns a transcript generated by [OpenAI's Whisper](https://github.com/openai/whisper).

## Features

- üìÅ Drag-and-drop inspired upload card with live status updates.
- üß† Server-side transcription powered by Whisper with asynchronous execution.
- ‚ö° Model warm-up on startup to reduce the latency of the first request.
- üéØ Helpful error messages when uploads fail or Whisper is not installed.

## Prerequisites

- Python 3.10 or newer. (PyTorch binary wheels for Whisper are typically available for Python 3.10‚Äì3.11.)
- [FFmpeg](https://ffmpeg.org/download.html) available on your system path. Whisper relies on FFmpeg for decoding media files.

If you are using Python 3.12+, you may need to build PyTorch from source or create a virtual environment with Python 3.10/3.11 so that `openai-whisper` can install all dependencies.

## Installation

1. Create and activate a virtual environment:

   ```bash
   python -m venv .venv
   source .venv/bin/activate  # On Windows use `.venv\\Scripts\\activate`
   ```

2. Install the dependencies:

   ```bash
   pip install --upgrade pip
   pip install -r requirements.txt
   ```

   Installing `openai-whisper` will pull in PyTorch and other dependencies. This step can take several minutes.

## Running the app

Start the API (and serve the frontend) with Uvicorn:

```bash
uvicorn app.main:app --reload
```

Then open <http://localhost:8000> in your browser. Upload an audio or video file to receive its transcript.

## API

### `POST /api/transcribe`

Accepts a multipart form upload with a single `file` field and returns JSON with the detected text:

```json
{
  "text": "Hello world"
}
```

Possible error responses use standard FastAPI error envelopes and return HTTP 400 with a `detail` string explaining what went wrong (empty file, unsupported format, Whisper not installed, etc.).

## Development notes

- The Whisper model name defaults to `base`. Adjust `TranscriptionService(model_name=...)` in `app/main.py` if you prefer a different size.
- Model loading happens lazily and is offloaded to a background thread so the FastAPI event loop stays responsive.
- Static assets live in `app/static` and are served directly by FastAPI.

## Troubleshooting

- **`openai-whisper` fails to install**: Ensure you are using a Python version with compatible PyTorch wheels (3.10 or 3.11 at the time of writing) and that you have internet access to download the large dependencies.
- **FFmpeg errors**: Confirm that `ffmpeg` is installed and accessible from your shell. On macOS you can install it with Homebrew (`brew install ffmpeg`); on Ubuntu use `sudo apt install ffmpeg`.
